{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72386200-095d-43f7-88c3-637841d3d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the TIF imagery and binary mask\n",
    "with rasterio.open('/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/30_bands_final.tif') as src:\n",
    "    imagery = src.read(1).astype(np.float32)\n",
    "\n",
    "with rasterio.open('/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/Mask.tif') as src:\n",
    "    mask = src.read(1).astype(np.uint8)\n",
    "\n",
    "# Create a valid mask excluding NaN values\n",
    "valid_mask = ~np.isnan(imagery)\n",
    "\n",
    "# Flatten the imagery and mask arrays to 1D\n",
    "X = imagery[valid_mask].reshape(-1, 1)\n",
    "y = mask[valid_mask].reshape(-1)\n",
    "\n",
    "# Define class names and their corresponding indices\n",
    "class_names = ['non-peat', 'peat']\n",
    "class_indices = [0, 1]\n",
    "\n",
    "# Keep only the valid classes '0' (non-peat) and '1' (peat)\n",
    "valid_classes_mask = np.isin(y, class_indices)\n",
    "X = X[valid_classes_mask]\n",
    "y = y[valid_classes_mask]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44858359-6e30-417b-a80d-01eba198ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search to find the best hyperparameters for the SVM model\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "svm_model = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best SVM model from grid search\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the best SVM model as .sav file\n",
    "joblib.dump(best_svm_model, '/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/svm_model.sav')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e2a07-8d5c-446a-94f9-c421b41c343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prediction probabilities for each class\n",
    "prediction_probabilities = best_svm_model.predict_proba(X_test)\n",
    "\n",
    "# Categorize probabilities into confidence intervals\n",
    "conf_intervals = [0, 0.45, 0.60, 0.90, 0.95, 1.0]\n",
    "interval_labels = ['Very Low Confidence', 'Low Confidence', 'Intermediate Confidence', 'High Confidence', 'Very High Confidence']\n",
    "\n",
    "# Create empty arrays for each confidence interval\n",
    "probabilities_peat_intervals = np.zeros_like(prediction_probabilities[:, 1], dtype=np.uint8)\n",
    "probabilities_no_peat_intervals = np.zeros_like(prediction_probabilities[:, 0], dtype=np.uint8)\n",
    "\n",
    "# Categorize probabilities for peat class\n",
    "for i in range(len(conf_intervals) - 1):\n",
    "    mask = (conf_intervals[i] <= prediction_probabilities[:, 1]) & (prediction_probabilities[:, 1] < conf_intervals[i + 1])\n",
    "    probabilities_peat_intervals[mask] = i + 1\n",
    "\n",
    "# Categorize probabilities for non-peat class\n",
    "for i in range(len(conf_intervals) - 1):\n",
    "    mask = (conf_intervals[i] <= prediction_probabilities[:, 0]) & (prediction_probabilities[:, 0] < conf_intervals[i + 1])\n",
    "    probabilities_no_peat_intervals[mask] = i + 1\n",
    "\n",
    "# Calculate percentages for each confidence interval\n",
    "percentages_peat = [np.sum(probabilities_peat_intervals == i) / len(probabilities_peat_intervals) for i in range(1, len(interval_labels) + 1)]\n",
    "percentages_no_peat = [np.sum(probabilities_no_peat_intervals == i) / len(probabilities_no_peat_intervals) for i in range(1, len(interval_labels) + 1)]\n",
    "\n",
    "# Plot the bar graph\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(interval_labels))\n",
    "\n",
    "plt.bar(index, percentages_peat, bar_width, label='Peat', color='green')\n",
    "plt.bar(index + bar_width, percentages_no_peat, bar_width, label='Non-Peat', color='blue')\n",
    "\n",
    "plt.xlabel('Confidence Intervals')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Confidence Intervals for Peat and Non-Peat')\n",
    "plt.xticks(index + bar_width / 2, interval_labels, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e24c9-0de6-4a6d-85b4-aeb5821f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix, precision, recall, F1 score, and accuracy\n",
    "y_pred = best_svm_model.predict(X_test)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_mat)\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec7956-6e9a-4779-85eb-82ab36a043a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction probabilities of peat and non-peat as separate TIF files\n",
    "probabilities_peat = np.zeros_like(imagery, dtype=np.float32)\n",
    "probabilities_no_peat = np.zeros_like(imagery, dtype=np.float32)\n",
    "probabilities_peat[valid_mask] = prediction_probabilities[:, 1]\n",
    "probabilities_no_peat[valid_mask] = prediction_probabilities[:, 0]\n",
    "\n",
    "with rasterio.open('/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/probability_peat.tif', 'w', driver='GTiff', height=imagery.shape[0], width=imagery.shape[1], count=1, dtype=np.float32, crs=src.crs, transform=src.transform) as dst:\n",
    "    dst.write(probabilities_peat, 1)\n",
    "\n",
    "with rasterio.open('/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/probability_no_peat.tif', 'w', driver='GTiff', height=imagery.shape[0], width=imagery.shape[1], count=1, dtype=np.float32, crs=src.crs, transform=src.transform) as dst:\n",
    "    dst.write(probabilities_no_peat, 1)\n",
    "\n",
    "# Save the classified image as a new TIF file\n",
    "classified_output = np.zeros_like(imagery, dtype=np.uint8)\n",
    "classified_output[valid_mask] = y_pred\n",
    "with rasterio.open('/home/jovyan/Desktop/shivanshi thesis/Tushar/Internship/classified_image.tif', 'w', driver='GTiff', height=imagery.shape[0], width=imagery.shape[1], count=1, dtype=np.uint8, crs=src.crs, transform=src.transform) as dst:\n",
    "    dst.write(classified_output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a3494-b666-4e88-9a29-f1ab7adc66c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
